{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_PATH = \"openai/whisper-large-v2\"\n",
    "AUDIO_PATH = \"./audio\"\n",
    "OUTPUT_PATH = \"./output/transformers/\"\n",
    "REPORT_PATH = \"./reports\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T12:17:56.337076Z",
     "start_time": "2024-03-10T12:17:56.334280Z"
    }
   },
   "id": "58a065286efd9d86",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v2\",\n",
    "    chunk_length_s=30,\n",
    "    device=\"cuda\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63c099060323b85c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "files = [\n",
    "]\n",
    "batch_sizes = [1, 2, 4, 8]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T12:18:06.298343Z",
     "start_time": "2024-03-10T12:18:06.295389Z"
    }
   },
   "id": "8e5c6b65babf9b91",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reports = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T12:18:06.309172Z",
     "start_time": "2024-03-10T12:18:06.298343Z"
    }
   },
   "id": "2fd38bf216f89816",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for b in batch_sizes:\n",
    "    reports = []\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    for f in files:\n",
    "        print(f\"Starting file {f} @ {b} batch size\")\n",
    "        sample, sr = torchaudio.load(f\"{AUDIO_PATH}/{f}\")\n",
    "        sample = torchaudio.functional.resample(\n",
    "            sample, orig_freq=sr, new_freq=16000\n",
    "        ).numpy()\n",
    "        s = perf_counter()\n",
    "        prediction = pipe(\n",
    "            sample[0].copy(), batch_size=b, return_timestamps=True,\n",
    "            generate_kwargs={\n",
    "                \"task\": \"transcribe\", \"language\": \"polish\",\n",
    "                \"do_sample\": False\n",
    "            }\n",
    "        )[\"chunks\"]\n",
    "        e = perf_counter()\n",
    "        print(f\"It took {e-s}\")\n",
    "        memory = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
    "        reports.append({f\"{f}\": f\"{e-s:.2f} s with {memory:.2f} MB used\"})\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        with open(\n",
    "                f\"{OUTPUT_PATH}/{f}-{b}-float32.txt\", \"w\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            f.write(\"\".join([s[\"text\"] for s in prediction]))\n",
    "    with open(f\"{REPORT_PATH}/transformers-{b}-float32.txt\", \"a\") as f:\n",
    "        for r in reports:\n",
    "            for k, v in r.items():\n",
    "                f.write(f\"{k}: {v}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b207933ddc5f69cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4bbfce0bc601d31e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
